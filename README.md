# MBTI Personality Type Classification

This project demonstrates an approach to classifying MBTI (Myers-Briggs Type Indicator) personality traits based on textual data using a machine learning pipeline. The dataset contains posts associated with MBTI types, and the goal is to predict individual dimensions of the MBTI type.

## Project Overview
The notebook preprocesses a dataset of MBTI personality types and text posts, applies text cleaning and feature extraction, and trains a multi-output Naive Bayes classifier to predict the MBTI traits (I/E, S/N, T/F, J/P) from the text posts. The workflow includes data cleaning, feature engineering using TF-IDF, and model training with evaluation metrics.

## Dataset
The dataset used is `mbti_dataset.csv`, with the following columns:
- **`type`**: The MBTI personality type (e.g., INFJ, ENTP).
- **`posts`**: A collection of text posts for each personality type.

### Additional Columns
The MBTI type is decomposed into four binary columns representing each personality trait:
- **`I/E`**: Introversion (0) vs. Extraversion (1)
- **`S/N`**: Sensing (0) vs. Intuition (1)
- **`T/F`**: Thinking (0) vs. Feeling (1)
- **`J/P`**: Judging (0) vs. Perceiving (1)

## Workflow
### 1. Preprocessing
- URLs, non-alphanumeric characters, and numbers are removed from the text posts.
- Text is converted to lowercase for uniformity.

### 2. Feature Engineering
- TF-IDF vectorization is applied to transform the text into numerical features for machine learning.

### 3. Model Training
- A `MultiOutputClassifier` with a `MultinomialNB` (Naive Bayes) estimator is used to predict the four MBTI traits simultaneously.

### 4. Evaluation
- Predictions are evaluated using precision, recall, and F1-score, as generated by the `classification_report` from `sklearn`.

## Key Results
The classification results for each MBTI trait were summarized with metrics like precision, recall, and F1-score. While the recall for certain traits was high, precision and F1-scores varied across traits, indicating room for improvement in the model.

## Requirements
This project requires the following Python libraries:
- `pandas`
- `scikit-learn`
- `re`

You can install these libraries using:
```bash
pip install pandas scikit-learn
```

## How to Run
1. Place the dataset (`mbti_dataset.csv`) in the same directory as the notebook.
2. Open the notebook and run all cells sequentially.
3. View the classification report output for model performance metrics.

## Future Improvements
- Experiment with advanced feature extraction techniques such as word embeddings (e.g., Word2Vec, GloVe, BERT).
- Optimize the model using hyperparameter tuning.
- Evaluate the model on a more balanced dataset to address potential class imbalance.
- Explore alternative machine learning models such as Random Forests or deep learning approaches.

## License
This project is released under the MIT License. Feel free to use and modify the code for your own purposes.
